{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venkatesh Prasad Venkataramanan PID : A53318036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import MNISTtools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.7037e+34, 4.5675e-41, 5.6992e+34],\n",
      "        [4.5675e-41, 5.7038e+34, 4.5675e-41],\n",
      "        [5.6993e+34, 4.5675e-41, 5.7022e+34],\n",
      "        [4.5675e-41, 6.6279e+34, 4.5675e-41],\n",
      "        [5.7059e+34, 4.5675e-41, 5.7059e+34]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5 , 3)\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X was initialised as a tensor object from PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1377, 0.8655, 0.2795],\n",
      "        [0.9360, 0.5037, 0.7908],\n",
      "        [0.2819, 0.2305, 0.8202],\n",
      "        [0.4840, 0.0554, 0.6504],\n",
      "        [0.0875, 0.5708, 0.1319]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.0705, -0.9844, -0.9151],\n",
      "        [-0.6822,  0.0144, -0.3439],\n",
      "        [-0.7303, -1.0881, -0.6431],\n",
      "        [ 0.1751, -1.0674, -1.5497],\n",
      "        [-0.4476, -0.8006,  0.5768]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5 , 3)\n",
    "print(y)\n",
    "print(type(y))\n",
    "y2 = torch.randn(5 , 3)\n",
    "print(y2)\n",
    "print(type(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, y is a Torch Tensor.\\\n",
    "The rand function produces a uniform distribution between 0 and 1.\\\n",
    "The randn function produces a normalised distribution with mean 0, variance 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.7037e+34, 4.5675e-41, 5.6992e+34],\n",
      "        [4.5675e-41, 5.7038e+34, 4.5675e-41],\n",
      "        [5.6993e+34, 4.5675e-41, 5.7022e+34],\n",
      "        [4.5675e-41, 6.6279e+34, 4.5675e-41],\n",
      "        [5.7059e+34, 4.5675e-41, 5.7059e+34]], dtype=torch.float64)\n",
      "tensor([[0.1377, 0.8655, 0.2795],\n",
      "        [0.9360, 0.5037, 0.7908],\n",
      "        [0.2819, 0.2305, 0.8202],\n",
      "        [0.4840, 0.0554, 0.6504],\n",
      "        [0.0875, 0.5708, 0.1319]], dtype=torch.float64)\n",
      "torch.DoubleTensor\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(x.type())\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x and y are both Torch Double Tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859,  1.3970,  0.5236],\n",
    "                  [ 2.3854,  0.0707,  2.1970],\n",
    "                  [-0.3587,  1.2359,  1.8951],\n",
    "                  [-0.1189, -0.1376,  0.4647],\n",
    "                  [-1.8968,  2.0164,  0.1092]])\n",
    "y = torch.Tensor([[ 0.4838,  0.5822,  0.2755],\n",
    "                  [ 1.0982,  0.4932, -0.6680],\n",
    "                  [ 0.7915,  0.6580, -0.5819],\n",
    "                  [ 0.3825, -1.1822,  1.5217],\n",
    "                  [ 0.6042, -0.2280,  1.3210]])\n",
    "\n",
    "print (x.shape)\n",
    "print (y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of x and y is [5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x,y))\n",
    "z2 = torch.cat((x,y),0)\n",
    "z3 = torch.cat((x,y),1)\n",
    "print(z.shape)\n",
    "print(z2.shape)\n",
    "print(z3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch stack function stacks into a three dimensional tensor.\\\n",
    "The cat function concatenates along a particular axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])\n",
    "print(z[1,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1092, 1.3210])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(z[:,4,2])\n",
    "print(len(z[:,4,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)\n",
    "print(torch.add(x,y))\n",
    "print(x.add(y))\n",
    "torch.add(x,y,out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are printing the same output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.view(16) flattens a 4 * 4 vector into a 1 * 16 vector.\\\n",
    "x.view(-1,8) keeps one axis to be 8, and calculates the other axis as per x's dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.3214,  11.2763]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(10,10)\n",
    "y=torch.randn(2,100)\n",
    "x2=x.view(1,100)\n",
    "y2=y.view(100,2)\n",
    "res=torch.mm(x2,y2)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)\n",
    "\n",
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a is a torch tensor.\\\n",
    "b is a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0]+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They match. They share underlying memory locations, as we can see that, b is changing, as a is changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.]) [3. 2. 2. 2. 2.]\n",
      "tensor([4., 3., 3., 3., 3.]) [4. 3. 3. 3. 3.]\n",
      "tensor([5., 4., 4., 4., 4.]) [4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a,b)\n",
    "a[:]+=1\n",
    "print(a,b)\n",
    "a=a.add(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observation, one can say that, a.add_(1) and a[:]+=1 is also modifying b.\\\n",
    "But, a.add(1) does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the question, torch tensors support conversion to numpy and back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "x = torch.randn(5, 3).to(device)\n",
    "y = torch.randn(5, 3, device=device)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x has been created on the cpu first, and then transferred to GPU.\\\n",
    "y has been created directly on the GPU, so it is more efficient in comparison, since transfers between CPU and GPU are expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.1995711  -2.9684575   0.63747984]\n",
      " [-0.9683557  -1.1878556  -0.1688531 ]\n",
      " [-0.02476832  0.1635682   0.2107917 ]\n",
      " [ 1.0837587   0.42707998  0.11120033]\n",
      " [-1.9955192  -0.04232109  1.970746  ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-11d5c486e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are converting z to cpu location first, then converting to numpy.\\\n",
    "Since z is now existing on CUDA, we can't convert to numpy. We need to convert to CPU first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "True\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.requires_grad)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requires_grad attribute of y is True.\\\n",
    "The grad attribute of x is None .\\\n",
    "The grad attribute of y is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*3\n",
    "f=z.mean()\n",
    "print(z,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation has been attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation has been attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(60000,)\n",
      "(784, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, ltrain = MNISTtools.load(dataset = \"training\", path = \"/datasets/MNIST\")\n",
    "xtest, ltest = MNISTtools.load(dataset = \"testing\", path = \"/datasets/MNIST\")\n",
    "print(xtrain.shape)\n",
    "print(ltrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ltest.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain = MNISTtools.load(dataset=\"training\", path=\"/datasets/MNIST\")#loaded data\n",
    "xtest, ltest = MNISTtools.load(dataset = \"testing\", path = \"/datasets/MNIST\")\n",
    "\n",
    "xtrain = xtrain.astype(np.float32)#float conversion\n",
    "xtest = xtest.astype(np.float32)\n",
    "\n",
    "def normalize_MNIST_images(x):\n",
    "    x = -1.0 + (2*x)/255#mapping [0,255] to [-1,1]\n",
    "    return x\n",
    "\n",
    "\n",
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "xtest = normalize_MNIST_images(xtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 60000)\n",
      "(28, 28, 1, 10000)\n"
     ]
    }
   ],
   "source": [
    "xtrain = np.reshape(xtrain,(28,28,1,60000))\n",
    "print (xtrain.shape)\n",
    "\n",
    "\n",
    "xtest = np.reshape(xtest,(28,28,1,10000))\n",
    "print (xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "xtrain = np.transpose(xtrain.reshape(28,28,1,60000),[3,2,0,1])\n",
    "xtest = np.transpose(xtest.reshape(28,28,1,10000),[3,2,0,1])\n",
    "\n",
    "print (xtrain.shape)\n",
    "print (xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "MNISTtools.show(xtrain[42,0,:,:])\n",
    "print(ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input image is 28 * 28 pixels.\\\n",
    "(i)   After the first convolutional layer, we have the size as 6 * 24 * 24.\\\n",
    "(ii)  After the maxpooling layer, we have size as 6 * 12 * 12.\\\n",
    "(iii) After the second convolutional layer, we have the size as 16 * 8 * 8.\\\n",
    "(iv)  After the maxpooling layer, we have the size as 16 * 4 * 4.\\\n",
    "So input at (v) has 256 units. \n",
    "\n",
    "Then we use a linear network to convert to 120 units.\n",
    "Then to 84 units.\n",
    "Then to 10 output units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1   = nn.Linear(16*4*4,120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learnable parameters are thus:\n",
    "\n",
    "Weight of the 1st Convolutional Neural Network.\n",
    "Bias of the 1st Convolutional Neural Network.\n",
    "\n",
    "Weight of the 2nd Convolutional Neural Network.\n",
    "Bias of the 2nd Convolutional Neural Network.\n",
    "\n",
    "Weight of the 1st Fully Connected Layer.\n",
    "Bias of the 1st Fully Connected Layer.\n",
    "\n",
    "Weight of the 2nd Fully Connected Layer.\n",
    "Bias of the 2nd Fully Connected Layer.\n",
    "\n",
    "Weight of the 3rd Fully Connected Layer.\n",
    "Bias of the 3rd Fully Connected Layer.\n",
    "\n",
    "They are going to be tracked for all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.7200)\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a random net, we are getting 1/10th of our predictions correctly, which is logical, since a random guess would have 10% probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = 600            # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.302\n",
      "[1,   200] loss: 2.297\n",
      "[1,   300] loss: 2.290\n",
      "[1,   400] loss: 2.280\n",
      "[1,   500] loss: 2.259\n",
      "[1,   600] loss: 2.216\n",
      "[2,   100] loss: 2.085\n",
      "[2,   200] loss: 1.628\n",
      "[2,   300] loss: 0.951\n",
      "[2,   400] loss: 0.592\n",
      "[2,   500] loss: 0.476\n",
      "[2,   600] loss: 0.394\n",
      "[3,   100] loss: 0.330\n",
      "[3,   200] loss: 0.299\n",
      "[3,   300] loss: 0.275\n",
      "[3,   400] loss: 0.247\n",
      "[3,   500] loss: 0.241\n",
      "[3,   600] loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = 600            # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(NB)\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            i = shuffled_indices[k]\n",
    "            minibatch_indices = range(i*B,i*B+B)\n",
    "            inputs = xtrain[minibatch_indices]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we get a loss of 0.243, which is very close to the expected value of 0.22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.0700)\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 94.07%, which is a huge improvement to the 9.72% we got off the initialised network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.304\n",
      "[1,   200] loss: 2.299\n",
      "[1,   300] loss: 2.295\n",
      "[1,   400] loss: 2.289\n",
      "[1,   500] loss: 2.280\n",
      "[1,   600] loss: 2.263\n",
      "[2,   100] loss: 2.227\n",
      "[2,   200] loss: 2.130\n",
      "[2,   300] loss: 1.790\n",
      "[2,   400] loss: 1.150\n",
      "[2,   500] loss: 0.810\n",
      "[2,   600] loss: 0.583\n",
      "[3,   100] loss: 0.477\n",
      "[3,   200] loss: 0.393\n",
      "[3,   300] loss: 0.352\n",
      "[3,   400] loss: 0.298\n",
      "[3,   500] loss: 0.277\n",
      "[3,   600] loss: 0.265\n",
      "[4,   100] loss: 0.228\n",
      "[4,   200] loss: 0.218\n",
      "[4,   300] loss: 0.217\n",
      "[4,   400] loss: 0.188\n",
      "[4,   500] loss: 0.187\n",
      "[4,   600] loss: 0.175\n",
      "[5,   100] loss: 0.164\n",
      "[5,   200] loss: 0.158\n",
      "[5,   300] loss: 0.162\n",
      "[5,   400] loss: 0.148\n",
      "[5,   500] loss: 0.153\n",
      "[5,   600] loss: 0.141\n",
      "[6,   100] loss: 0.129\n",
      "[6,   200] loss: 0.134\n",
      "[6,   300] loss: 0.127\n",
      "[6,   400] loss: 0.131\n",
      "[6,   500] loss: 0.120\n",
      "[6,   600] loss: 0.119\n",
      "[7,   100] loss: 0.116\n",
      "[7,   200] loss: 0.123\n",
      "[7,   300] loss: 0.108\n",
      "[7,   400] loss: 0.104\n",
      "[7,   500] loss: 0.115\n",
      "[7,   600] loss: 0.096\n",
      "[8,   100] loss: 0.116\n",
      "[8,   200] loss: 0.092\n",
      "[8,   300] loss: 0.096\n",
      "[8,   400] loss: 0.100\n",
      "[8,   500] loss: 0.095\n",
      "[8,   600] loss: 0.093\n",
      "[9,   100] loss: 0.089\n",
      "[9,   200] loss: 0.087\n",
      "[9,   300] loss: 0.091\n",
      "[9,   400] loss: 0.088\n",
      "[9,   500] loss: 0.084\n",
      "[9,   600] loss: 0.093\n",
      "[10,   100] loss: 0.076\n",
      "[10,   200] loss: 0.081\n",
      "[10,   300] loss: 0.087\n",
      "[10,   400] loss: 0.086\n",
      "[10,   500] loss: 0.073\n",
      "[10,   600] loss: 0.085\n"
     ]
    }
   ],
   "source": [
    "xtrain = xtrain.to(device)\n",
    "ltrain = ltrain.to(device)\n",
    "net = LeNet().to(device)\n",
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = xtest.to(device)\n",
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.9200, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ltest = ltest.to(device)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has improved from 94.07% to 97.92% , after running for 10 iterations. \\\n",
    "Hence we achieve an accuracy of nearly 98%, which is an improvement to the 96% we got off the artificial neural network-based classifier in assignment 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
